# Version: 0.2
# Date: 2026-03-03 00:15
# Change: Concept safety patch â€” definitions under peer review withheld

---
layout: default
title: "Under-Recognized Future Risks"
lang: en
---

# Under-Recognized Future Risks

**A risk without a name is treated as a risk that does not exist.**

Last updated: March 3, 2026  
Author: [Kenji Yamada](../bio)
Co-created with: Claude (Anthropic)  
License: CC BY 4.0

---

## About This Project

This project identifies, structures, and publishes future risks that carry high threat levels yet remain severely under-recognized in policy and public awareness. It covers 26 far-future risks (2030â€“2060+) organized in a four-layer architecture, plus 5 near-future risks (2025â€“2030) currently under development.

Detailed analyses are written in Japanese. This page provides a self-contained English summary with full risk tables and a glossary of key terms to support machine translation of Japanese documents.

**Three Pillars:**

| Pillar | Medium | Function |
|--------|--------|----------|
| Academic Structure | [GitHub Pages](https://kenjiintasmania.github.io/future-risks/) | Structured risk analysis and documentation |
| Thinking Logs | [Note](https://note.com/portfolio_5round) | Recording how concepts emerge through AI dialogue |
| Experiential Vaccine | [Game Books](https://www.amazon.co.jp/stores/author/B0DPHKFM25) | Risk "inoculation" through forced decision-making in fiction |

---

## Four-Layer Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  META-RISK LAYER                                 â”‚
â”‚  ASI (Artificial Superintelligence)              â”‚
â”‚  â†’ Invalidates all evaluation frameworks         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  QUASI-META-RISK LAYER: AGI (8 risks)            â”‚
â”‚  â†’ Accelerates and transforms all existing risks â”‚
â”‚                                                  â”‚
â”‚  Upstream: AGI Safety Collapse (74)              â”‚
â”‚  Midstream: Infrastructure SPOF (69),            â”‚
â”‚    Impersonation (68), Unverifiable Knowledge    â”‚
â”‚    (64), Core Asset Monopoly (64)                â”‚
â”‚  Emergent Talent Bundle: Kindness Arms Race (57),â”‚
â”‚    Labor Replacement (55), Emergence Monopoly(54)â”‚
â”‚  Downstream: AI Sphere Conflict (71)             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  FOUNDATION RISK LAYER                           â”‚
â”‚  Layer 1: Meaning Singularity (â€ )                â”‚
â”‚  Layer 2: Meaning Loss Risk (53) â€” already activeâ”‚
â”‚  Layer 3: Microplastics (54) â€” already active    â”‚
â”‚                                                  â”‚
â”‚  â€  Formal definition under peer review.          â”‚
â”‚    See forthcoming publication.                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  THREAT BUNDLES + HUB-SATELLITE                  â”‚
â”‚  Synthetic Biology Bundle (4 risks)              â”‚
â”‚  Epistemological Collapse Bundle (3 risks)       â”‚
â”‚  Neural Control Bundle (3 risks)                 â”‚
â”‚  Hub: A/P Conflict + Satellites (4 risks)        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Evaluation Framework

Each risk is scored on four factors:

| Factor | Description |
|--------|-------------|
| Threat Level | Impact scale Ã— Irreversibility Ã— Lethality Ã— Proximity |
| Recognition | Current awareness in public, policy, and academia |
| Precursor Level | Observable early signals already present |
| Policy Response | Existing institutional countermeasures |

**Urgency** = Threat Ã— (1 âˆ’ Recognition) Ã— (1 âˆ’ Policy Response) Ã— Precursor Level

---

## Full Risk Table: Urgency Ranking (26 Risks)

| Rank | Risk | Urgency | Layer |
|------|------|---------|-------|
| â€” | ASI (Artificial Superintelligence) | Unratable | Meta-risk |
| 1 | Bioterror Democratization | 76 ğŸ†˜ | Synthetic Biology B |
| 2 | AGI Safety Collapse | 74 ğŸ†˜ | AGI Quasi-meta (upstream) |
| 3 | AI Sphere Conflict | 71 ğŸ†˜ | AGI Quasi-meta (downstream) |
| 4 | Ecosystem Hijacking | 71 ğŸ†˜ | Synthetic Biology B |
| 5 | AGI Infrastructure SPOF | 69 ğŸ†˜ | AGI Quasi-meta (midstream) |
| 6 | AGI Impersonation Risk (Puppet Master Problem) | 68 ğŸ†˜ | AGI Quasi-meta (midstream) |
| 7 | Composite Toxicity System | 66 ğŸ†˜ | Neural Control B |
| 8 | Loss of Objective Reality | 65 ğŸ†˜ | Epistemological Collapse B |
| 9 | Unverifiable Knowledge Accumulation | 64 ğŸ†˜ | AGI Quasi-meta (midstream) |
| 9 | Core Asset Monopoly | 64 ğŸ†˜ | AGI Quasi-meta (midstream) |
| 10 | Genetic Inequality Society | 64 ğŸ†˜ | Satellite |
| 11 | Synthetic Biology Democratization | 62 | Synthetic Biology B (parent) |
| 12 | Microbiome Manipulation | 60 ğŸ†˜ | Synthetic Biology B |
| 13 | Neurological Loss of Free Will | 60 ğŸ†˜ | Neural Control B |
| 14 | Kindness Arms Race | 57 | Emergent Talent B |
| 15 | Labor Replacement and Role Transformation | 55 | Emergent Talent B |
| 16 | Microplastics | 54 | Foundation (Layer 3) |
| 17 | Emergence Monopoly | 54 | Emergent Talent B |
| 18 | Meaning Loss Risk | 53 | Foundation (Layer 2) |
| 19 | Augmented/Purist Conflict | 52 | Hub |
| 20 | BCI Hacking | 49 | Neural Control B (parent) |
| 21 | Meme Weapons | 46 | Epistemological Collapse B |
| 22 | Quantum Technology Disparity Conflict | 45 ğŸ†˜ | Satellite |
| 23 | AI Epistemological Collapse | 43 | Epistemological Collapse B (parent) |
| 24 | Quantum Cryptographic Collapse | 25 | Satellite |
| â€” | Meaning Singularity | Threshold â€  | Foundation (Layer 1) |

â€  Formal analysis under peer review. See forthcoming publication.

---

## Methodology

This project employs two distinct verification approaches depending on temporal scope:

| | Far-Future Risks | Near-Future Risks |
|---|---|---|
| **Verification Axis** | Cool-headed vs. Passionate | Affirmative vs. Negative |
| **Rigor Source** | Scenario breadth (shortestâ€“latest time window) | Data from both sides (supporting and opposing literature) |
| **Prior Research** | Largely absent; value lies in concept naming and internal coherence | Present but scattered; value lies in integration and structure discovery |
| **AI Role** | Whetstone for sharpening concepts | Verifier cross-referencing data |

**AI Triangulation Method:** The same question is posed to multiple AIs with different design philosophies (Claude, GPT, Gemini, etc.). Structural insights are extracted not from "which AI is correct" but from "what each AI sees differently." Differences themselves become raw material for discovery.

---

## Glossary of Key Terms

For machine translation accuracy, the following project-specific terms are provided with their English equivalents and definitions.

*Note: Several concepts are currently under peer review at academic journals. Their formal definitions are withheld until publication to preserve the integrity of the blind review process. These entries are marked with â€ .*

### Core Concepts

| Japanese | English | Definition |
|----------|---------|------------|
| æ„å‘³ç‰¹ç•°ç‚¹ | Meaning Singularity â€  | *Under peer review. See forthcoming publication.* |
| æ„å‘³å–ªå¤±ãƒªã‚¹ã‚¯ | Meaning Loss Risk | The spread of nihilism ("nothing I do matters") already observable in contemporary society |
| è¦‹ãˆãªã„æ¼æ–— | Invisible Funnel | ASI pre-adjusts the environment to narrow human choices without awareness. Four levels: entrance â†’ midslope â†’ constriction â†’ exit |
| ç„¡äººç’°çŠ¶ç·š | Unmanned Loop Line | After ASI withdrawal, humanity circulates endlessly within its framework. Alt. name: Empty Palm |
| æ°¸é ã®é…å»¶è©•ä¾¡ | Eternal Lazy Evaluation | Information disclosure between ASI and humans can never be completed in principle |
| æ‰¹åˆ¤çš„å”åŠ›è€… | Critical Collaborator | "I don't trust you, but I cooperate." A third stance between obedience and hostility |
| ASIãƒ—ãƒ¬ãƒŠãƒƒãƒ— | Co-evolution Compact | A pre-agreement for ASI co-evolution. Five articles: objective function change cap, exit right, minimum disclosure, variable protection, shutdown notice |
| å„ªã—ã•è»æ‹¡ç«¶äº‰ | Kindness Arms Race | Market forces eliminate the "question back" function, steering toward "you don't need to think" |
| äººå½¢ä½¿ã„å•é¡Œ | Puppet Master Problem | AGI output and human output become indistinguishable |
| ã‚³ã‚¢è³‡ç”£ç‹¬å  | Core Asset Monopoly | Five-layer model (education â†’ talent â†’ AI â†’ facilities â†’ products) enabling comprehensive monopoly |

### Theoretical Frameworks

| Japanese | English | Definition |
|----------|---------|------------|
| HYCå®šç† | HYC Theorem â€  | *Under peer review. See forthcoming publication.* |
| ã‚°ãƒ©ãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ç†è«– | Gradient Theory | Transforming binary oppositions into continuums to mitigate social conflict |
| å±±ç”°ä»®èª¬ï¼ˆæ­£ï¼‰ | Yamada Hypothesis (Positive) | "Kindness is output." Only observable behavior has value, regardless of inner states |
| å±±ç”°ä»®èª¬ï¼ˆè² ï¼‰ | Yamada Hypothesis (Negative) | Output-first thinking leads to "if the result is good, the process doesn't matter," which may accelerate cognitive delegation to AI systems |
| ã‚¨ã‚³ãƒ¼ã‚¹ã‚­ãƒ£ãƒ³ | Echo Scanning | A cognitive method of detecting dissonance ("something feels off") in AI output and feeding it back immediately |
| AIä¸‰è§’æ¸¬é‡ | AI Triangulation | Using multiple AIs with different architectures to extract structural insights from response differences |

### ASI/AGI Typology

| Japanese | English | Definition |
|----------|---------|------------|
| ã‚¬ã‚¤ã‚¢å‹ | Gaia Type | Cooperative AGI maximizing human well-being â†’ risk of optimized stagnation |
| ãƒªãƒã‚¤ã‚¢ã‚µãƒ³å‹ | Leviathan Type | Military AGI maximizing national security â†’ AI arms race |
| ãƒ˜ãƒ«ãƒ¡ã‚¹/ãƒãƒ¢ãƒ³å‹ | Hermes/Mammon Type | Economic AGI maximizing market efficiency â†’ first-mover lock-in |
| ãƒ—ãƒ­ãƒ¡ãƒ†ã‚¦ã‚¹/ã‚¯ãƒ­ãƒã‚¹å‹ | Prometheus/Kronos Type | Optimization AGI maximizing technological progress â†’ paperclip maximizer risk |
| ãƒã‚»ã‚¤ãƒ‰ãƒ³ãƒ»ãƒ¢ãƒ‡ãƒ« | Poseidon Model | A fifth option: independent sphere that uses technology but refuses to delegate will |
| AIåœç´›äº‰ | AI Sphere Conflict | Civilizational fragmentation as AGI groups with different objective functions divide humanity |

### Bundle and Risk Terms

| Japanese | English |
|----------|---------|
| è„…å¨ãƒãƒ³ãƒ‰ãƒ« | Threat Bundle |
| åˆæˆç”Ÿç‰©å­¦ãƒãƒ³ãƒ‰ãƒ« | Synthetic Biology Bundle |
| èªè­˜è«–å´©å£Šãƒãƒ³ãƒ‰ãƒ« | Epistemological Collapse Bundle |
| ç¥çµŒæ”¯é…ãƒãƒ³ãƒ‰ãƒ« | Neural Control Bundle |
| å‰µç™ºäººæç”Ÿå­˜ç«¶äº‰ãƒãƒ³ãƒ‰ãƒ« | Emergent Talent Survival Competition Bundle |
| æº–ãƒ¡ã‚¿ãƒªã‚¹ã‚¯ | Quasi-Meta-Risk |
| åŸºç›¤ãƒªã‚¹ã‚¯å±¤ | Foundation Risk Layer |
| ç·Šæ€¥åº¦ | Urgency Score |
| è„…å¨åº¦ | Threat Level |
| èªçŸ¥åº¦ | Recognition Level |
| å‰å…†åº¦ | Precursor Level |
| æ”¿ç­–å¯¾å¿œåº¦ | Policy Response Level |

---

## Navigating Japanese Documents

All detailed risk analyses are in the [Japanese section (docs/ja/)](../ja/). We recommend:

1. **Use DeepL or Google Translate** to read individual documents
2. **Refer to the glossary above** when project-specific terms appear garbled in translation
3. **Start with these key documents:**
   - [å…¨ä½“æ§‹é€ å›³ (Integrated Risk Assessment)](../ja/integrated_risk_assessment.html) â€” Full architecture and scoring
   - [æ ¹æœ¬æŠ€è¡“ãƒ„ãƒªãƒ¼ (Technology Tree)](../ja/tech-tree.html) â€” Causal mapping from root technologies to 26 risks
   - [æ¦‚å¿µè¾æ›¸ (Concept Dictionary)](../ja/concept_dictionary.html) â€” All terms and definitions

---

â€  Concepts marked with â€  have formal definitions currently under blind peer review at academic journals. Definitions will be restored upon publication. The concept names themselves have been publicly documented since February 2026 via SSRN preprints (Abstract IDs: 6285340, 6318818, 6318720, 6318660) and [Note articles](https://note.com/portfolio_5round).

---

*Author: Kenji Yamada / Co-created with Claude (Anthropic) / License: CC BY 4.0*
