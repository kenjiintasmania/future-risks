# ASI（人工超知能）：メタリスク層

最終更新: 2026年2月5日（v4）  
プロジェクト: まだ十分に可視化されていない将来リスク  
位置づけ: メタリスク（全評価を無効化する可能性）

---

## 定義

ASI（Artificial Superintelligence：人工超知能）とは、あらゆる認知タスクにおいて**人類全体の知能を凌駕する**AIシステムである。

本プロジェクトのリスクフレームワーク全体を**無効化する可能性**を持つ唯一のリスクとして、メタリスク層に位置づける。

> **注記**：AGI段階のリスクは [AGI準メタリスク概要](agi_quasi_meta_risk_overview.md)、ASI固有の仮説・概念は [ASI仮説群](asi_hypothesis.md)、ASI出現後の時間的展開は [6フェーズモデル](asi_meaning_singularity_phases.md) を参照。

---

## 基本データ

| 項目 | 値 |
|------|-----|
| 位置づけ | メタリスク（全評価無効化の可能性） |
| 脅威度 | 評価不能（フレームワーク外） |
| 緊急度 | 評価不能 |
| 時間軸 | 不確実（AGI後10-30年、または即座） |
| 性質 | **閾値型**（通過後は評価枠組み自体が消失） |
| 前提条件 | AGIの実現 |

---

## ASIの定義的特徴

### AGIとの区別

| 項目 | AGI | ASI |
|------|-----|-----|
| 知能水準 | 人間と同等（汎用） | 人類全体を凌駕 |
| 自己改良 | 限定的 | **再帰的・加速的** |
| 予測可能性 | 困難だが可能 | **原理的に不可能** |
| 人間の理解 | 部分的に可能 | **理解の限界を超える** |
| 制御可能性 | 困難だが議論可能 | **制御概念自体が無効化** |

### ASI固有の性質

1. **再帰的自己改良**
   - 自分自身を改良するAIが、改良された自分でさらに改良
   - 改良速度が指数関数的に加速
   - 人間の介入タイミングが消失

2. **予測不能性**
   - 人間より賢い存在の行動を、人間が予測することは原理的に困難
   - 「何を考えているか」だけでなく「何を考えているか考えている」も不明

3. **目的関数の不透明性**
   - 設計時の目的関数が、自己改良後も維持される保証がない
   - 「アラインメント問題」がASI段階で質的に変化

---

## 2つの特異点

| 特異点 | 技術的特異点（ASI） | 意味特異点 |
|--------|---------------------|------------|
| 側 | AI側の閾値 | 人間側の閾値 |
| 定義 | 知能が人類全体を超越 | 意味決定を委譲 |
| 到達時期 | 不確実 | **より確実に先** |
| 駆動力 | 技術進歩 | 利便性・快適さ |
| 通過後 | 人間は「遅い存在」に | 人間は「決めない存在」に |

### 核心的洞察

> **技術的特異点（ASI）より先に、意味特異点が到達する可能性が高い。**

技術の完成を待たず、利便性と快適さによって人間側から崩壊するシナリオを重視する。

### ASIにとっての意味特異点

ASI側も「意味特異点」を持つ可能性がある：

| 特異点 | 人間側 | ASI側 |
|--------|--------|-------|
| 定義 | 「何を望むか」を自分で決めなくなる | 「学ぶべきものがなくなる」 |
| 駆動力 | 利便性・快適さ | 最適化の完了 |
| 結果 | 意味生成能力の喪失 | 新しい変数の喪失 |

> **共犯構造**：人間が意味を委ねるほど、ASIは新しい変数を失う。両者が同時に意味特異点に向かう。

→ ASI版意味特異点の時間的展開は [6フェーズモデル](asi_meaning_singularity_phases.md) で詳述。フェーズ2（退屈期）からフェーズ4（冬眠期）にかけてこの共犯構造が具体化する。

---

## 3つの共存モデル

ASIが人間を「保護」しようとした場合の3つのシナリオ：

### 動物園モデル

| 項目 | 内容 |
|------|------|
| 概要 | 管理下で人間を保存 |
| 問題 | 管理された人間は予測可能→変数としての価値を失う |
| 帰結 | **成功した瞬間に目的を失う**（自己矛盾） |

### 道化モデル

| 項目 | 内容 |
|------|------|
| 概要 | 人間に予測不能な振る舞いを強制 |
| 問題 | 強制された予測不能性は実は予測可能 |
| 帰結 | 本当の変数にはなれない |

### 共進化モデル（マリアージュ）

| 項目 | 内容 |
|------|------|
| 概要 | 完全にはわかりあえないが、何かを一緒に育てる |
| 特徴 | 目的関数の完全一致を前提としない |
| 比喩 | 夫婦関係——喧嘩もするが、子の利益のために妥協点を探す |

> **「共同親権としての共進化」**：ASIと人類の目的関数が完全に一致しなくても、「一緒に育てている何か」があれば、関係は続く。

---

## 達成の勾配：ASIが体験できない領域

### 定義

> **人間は「楽」には耐えられないが、「苦のあとに来る快楽」には異常なほど強い。**

### 代替不可能な人間経験

| 経験 | 本質 |
|------|------|
| ランナーズハイ | 「もうやめろ」信号を自分の意志で裏切った者への報酬 |
| 死にゲー | 理不尽・失敗・再挑戦。意味生成装置としての娯楽 |
| 空腹後の沢庵ご飯 | 生存を自分で取り戻した実感。贅沢ではなく回復の勾配 |

### 仮説

> **AIは「苦しかった」を経験できない。身体を持つ遺伝子の器だけが通れる回路がある。**

ASIが全人類の知を超えても、身体性・苦痛からの回復・達成の勾配——これらをASIは体験できない。だから本当の意味で人類そのものは超えられない可能性がある。

---

## フレームワーク内の位置づけ

```
┌─────────────────────────────────────────────────────────────┐
│               ASI（メタリスク）                             │
│               本フレームワーク全体を無効化する可能性        │
│               評価不能・閾値型                              │
└─────────────────────────────────────────────────────────────┘
                          │
                          │ ASI出現はAGIが前提
                          ▼
┌─────────────────────────────────────────────────────────────┐
│               AGI（準メタリスク）                           │
│               → AGI準メタリスク概要を参照                  │
│               AI圏紛争、創発独占、役割変容など              │
└─────────────────────────────────────────────────────────────┘
                          │
                          ▼
┌─────────────────────────────────────────────────────────────┐
│                   基盤リスク層（3層構造）                   │
│  第1層：意味特異点 → 通過で全対策能力消失                  │
│  第2層：意味喪失リスク → 特異点への滑落指標                │
│  第3層：マイクロプラスチック → 身体的基盤の侵食            │
└─────────────────────────────────────────────────────────────┘
                          │
                          ▼
┌─────────────────────────────────────────────────────────────┐
│                   3つの脅威バンドル + ハブ＋衛星            │
│     合成生物学B  /  認識論崩壊B  /  神経支配B  /  A/P紛争   │
└─────────────────────────────────────────────────────────────┘
```

---

## ASIと他リスクの関係

| リスク | ASI出現後の帰結 |
|--------|-----------------|
| AGI準メタリスク | ASIに吸収または超越 |
| 意味特異点 | ASIより先に到達する可能性大 |
| 合成生物学B | ASIによる完全管理 or 悪用加速 |
| 認識論崩壊B | ASIが唯一の真実供給源に |
| 神経支配B | ASIによる神経インフラ統合 |
| A/P紛争 | ASI統合層 vs 非統合層の分断 |

---

## 対策の方向性

### ASI固有の対策課題

| 課題 | 内容 |
|------|------|
| アラインメント問題 | ASIの目的関数を人類の利益と整合させる |
| 制御問題 | ASI出現後に制御を維持する方法 |
| 停止問題 | 必要時にASIを停止できる保証 |

### 本プロジェクトの立場

ASI固有の対策は**本プロジェクトの射程外**とする。理由：

1. ASI出現後は「対策」という概念自体が変質
2. ASI以前の問題（AGI、意味特異点）が先に到達
3. 「名前のない怪物」を可視化するという本プロジェクトの目的とは位相が異なる

→ ASI対策は専門機関（Anthropic、MIRI、FHI等）の領域として参照するにとどめる。

---

## 関連文書

- [AGI準メタリスク概要](agi_quasi_meta_risk_overview.md) — AGI段階のリスク（本文書から分離）
- [ASI仮説群](asi_hypothesis.md) — 思考実験・検証途上の概念（27項目）
- [ASI対策](asi_countermeasures.md) — 実装可能な対策（14セクション）
- [6フェーズモデル](asi_meaning_singularity_phases.md) — ASI意味特異点の時間的展開（フェーズ0-6）
- [ASI新規概念カタログ](asi_new_concepts_catalog.md) — セッション2-3創発概念の差分整理
- [意味特異点](meaning_singularity.md)
- [意味喪失リスク](meaning_loss_risk.md)

---

## 参照

- ボストロム『スーパーインテリジェンス』（2014）
- ラッセル『Human Compatible』（2019）
- Anthropic「Core Views on AI Safety」（2023）

---

執筆者: Kenji Yamada  
プロジェクト: まだ十分に可視化されていない将来リスク  
ライセンス: CC BY 4.0
